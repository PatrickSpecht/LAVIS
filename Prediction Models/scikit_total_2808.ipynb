{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import sklearn\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speichern Systemzeit\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laden des Datensatzes\n",
    "data = pd.read_excel(r'masterlist_total_extrakt.xlsx')\n",
    "data = data.drop([data.columns[0]], axis='columns')\n",
    "\n",
    "#Entferne Features\n",
    "data = data.drop(['UNLOADING_mt','SETUP_mt', 'AVG_TEMPERATURE', 'AVG_VISIBILITY','Tiefgang', 'Breite'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeitreihenplot definieren\n",
    "from plotly.offline import plot \n",
    "import plotly.graph_objs as go \n",
    "\n",
    "def time_series_plot(y_test, predict, modelname):\n",
    "    xv = list(range(1,len(y_test))) \n",
    "    \n",
    "    trace_high = go.Scatter( \n",
    "        x=xv[1:150], \n",
    "        y=predict[1:150], \n",
    "        name = \"Modellschätzung\", \n",
    "        line = dict(color = '#008080'),\n",
    "        opacity = 0.8) \n",
    "    \n",
    "    trace_low = go.Scatter( \n",
    "        x=xv[1:150], \n",
    "        y=y_test[1:150], \n",
    "        name = \"Beobachteter Wert\", \n",
    "        line = dict(color = '#808080'), \n",
    "        opacity = 0.8) \n",
    "    \n",
    "    data = [trace_high, trace_low] \n",
    "    \n",
    "    layout = dict( \n",
    "        title = modelname + \" Modellschätzung vs. beobachtete Werte\", \n",
    "        yaxis=dict( \n",
    "            title='Dauer bis Endladeabschluss (min)'),\n",
    "        xaxis=dict( \n",
    "            title='Anläufe in Validierungsstichprobe'),\n",
    "        legend=dict(\n",
    "            yanchor=\"top\",\n",
    "            y=0.99,\n",
    "            xanchor=\"left\",\n",
    "            x=0.01),\n",
    "    ) \n",
    "    \n",
    "    fig = dict(data=data, layout=layout) \n",
    "    plot(fig, filename=modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sicherstellen, dass jede Ausführung die gleichen Zufallszahlen generiert.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schichtkriterium definieren. In diesem Fall sind die Schiffsklassen anhand ihrer TEU-Kapazität\n",
    "data['size_cat'] = pd.cut(data['TEU'], bins=[0,1000,2500,10000, np.inf], labels=[1,2,3,4])\n",
    "\n",
    "#Sampling durchführen\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=40)\n",
    "for train_index, test_index in split.split(data, data[\"size_cat\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schichtkriterium entfernen\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"size_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenbereinigung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unabhängige und abhängige Variablen definieren\n",
    "calls_3ft = strat_train_set.drop(['UNLOADING_TOTAL', 'AVG_WINDSPEED', 'AVG_RAINFALL'], axis=1)\n",
    "calls_5ft = strat_train_set.drop('UNLOADING_TOTAL', axis=1)\n",
    "calls_labels = strat_train_set['UNLOADING_TOTAL'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "calls_num_5ft = calls_5ft.drop(\"Terminal\", axis=1)\n",
    "calls_num_3ft = calls_3ft.drop(\"Terminal\", axis=1)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "num_attribs_5ft = list(calls_num_5ft)\n",
    "num_attribs_3ft = list(calls_num_3ft)\n",
    "cat_attribs = ['Terminal']\n",
    "\n",
    "full_pipeline_3ft = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs_3ft),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "full_pipeline_5ft = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs_5ft),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "calls_prepared_3ft = full_pipeline_3ft.fit_transform(calls_3ft)\n",
    "calls_prepared_5ft = full_pipeline_5ft.fit_transform(calls_5ft)\n",
    "\n",
    "\n",
    "#Export der Pipelines\n",
    "preprocessors = dict({\n",
    "                'full_pipeline_3ft': full_pipeline_3ft,\n",
    "                'full_pipeline_5ft': full_pipeline_5ft\n",
    "})\n",
    "\n",
    "joblib.dump(preprocessors, open(\"../../webapp/full_pipeline.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model initialisieren und trainieren\n",
    "from sklearn import linear_model\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(calls_prepared_3ft, calls_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [402.1191928  340.9517282  377.76845796 427.30968482 456.05173091\n",
      " 502.2290868  347.18143608 517.06423937 377.3722231  424.74148716]\n",
      "Mean: 417.27892671961644\n",
      "Standard deviation: 57.4075027100363\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren\n",
    "lin_scores = cross_val_score(lin_reg, calls_prepared_3ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model inkl. Metadaten exportieren\n",
    "lr_model = dict({\n",
    "    'model': lin_reg,\n",
    "    'metadata': {\n",
    "        'type': 'Linear Regression',\n",
    "        'date': now,\n",
    "        'metrics': {\n",
    "            'Cross-val-RSME': lin_rmse_scores.mean()\n",
    "        }\n",
    "    }\n",
    "})\n",
    "joblib.dump(lr_model, open(\"../../webapp/total_lin_reg.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entscheidungsbaum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modelle initialisieren und trainieren\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg_3ft = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg_3ft.fit(calls_prepared_3ft, calls_labels)\n",
    "tree_reg_5ft = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg_5ft.fit(calls_prepared_5ft, calls_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [388.57829465 314.35618055 367.92708738 433.78840536 452.01119901\n",
      " 464.89443905 317.49520512 490.12148651 353.2522615  420.36215771]\n",
      "Mean: 400.27867168510926\n",
      "Standard deviation: 58.378262836088176\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren (3ft)\n",
    "tree_scores = cross_val_score(tree_reg_3ft, calls_prepared_3ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores_3ft = np.sqrt(-tree_scores)\n",
    "display_scores(tree_rmse_scores_3ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [589.30994119 564.43116444 546.18807149 578.07902712 574.82265318\n",
      " 559.44941213 470.9917809  661.19140166 575.67258628 542.62687446]\n",
      "Mean: 566.2762912845444\n",
      "Standard deviation: 44.64531623982507\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren (5ft)\n",
    "tree_scores = cross_val_score(tree_reg_5ft, calls_prepared_5ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores_5ft = np.sqrt(-tree_scores)\n",
    "display_scores(tree_rmse_scores_5ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model inkl. Metadaten exportieren\n",
    "tree_model = dict({\n",
    "    'model': tree_reg_3ft,\n",
    "    'metadata': {\n",
    "        'type': 'Entscheidungsbaum',\n",
    "        'date': now,\n",
    "        'metrics': {\n",
    "            'Cross-val-RSME': tree_rmse_scores_3ft.mean()\n",
    "        }\n",
    "    }\n",
    "})\n",
    "joblib.dump(tree_model, open(\"../../webapp/total_tree_reg.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Neighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='brute', n_neighbors=13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model initialisieren und trainieren\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_reg_3ft = KNeighborsRegressor(n_neighbors=13, algorithm='brute')\n",
    "knn_reg_3ft.fit(calls_prepared_3ft, calls_labels)\n",
    "knn_reg_5ft = KNeighborsRegressor(n_neighbors=13, algorithm='brute')\n",
    "knn_reg_5ft.fit(calls_prepared_5ft, calls_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [386.68485281 323.76626463 384.24333535 413.82938291 456.31456346\n",
      " 466.21905702 310.88639428 488.58118536 376.4894771  426.1280311 ]\n",
      "Mean: 403.3142544022795\n",
      "Standard deviation: 55.58608677880107\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren (3ft)\n",
    "knn_scores = cross_val_score(knn_reg_3ft, calls_prepared_3ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "knn_rmse_scores_3ft = np.sqrt(-knn_scores)\n",
    "display_scores(knn_rmse_scores_3ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [422.51251416 354.26840662 388.26890009 437.64418509 463.40828096\n",
      " 511.7129713  347.05164799 528.48378727 387.05850549 440.21653372]\n",
      "Mean: 428.0625732689249\n",
      "Standard deviation: 58.20195581313722\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren (5ft)\n",
    "knn_scores = cross_val_score(knn_reg_5ft, calls_prepared_5ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "knn_rmse_scores_5ft = np.sqrt(-knn_scores)\n",
    "display_scores(knn_rmse_scores_5ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../webapp/total_knn_reg.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model inkl. Metadaten exportieren\n",
    "knn_model = dict({\n",
    "    'model': knn_reg_3ft,\n",
    "    'metadata': {\n",
    "        'type': 'K-Neighbors Regression',\n",
    "        'date': now,\n",
    "        'metrics': {\n",
    "            'Cross-val-RSME': knn_rmse_scores_3ft.mean()\n",
    "        }\n",
    "    }\n",
    "})\n",
    "joblib.dump(knn_model, \"../../webapp/total_knn_reg.joblib\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model initialisieren und trainieren\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg_3ft = RandomForestRegressor(random_state=42)\n",
    "forest_reg_3ft.fit(calls_prepared_3ft, calls_labels)\n",
    "forest_reg_5ft = RandomForestRegressor(random_state=42)\n",
    "forest_reg_5ft.fit(calls_prepared_5ft, calls_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [387.07117914 309.89864765 365.51228811 426.36824338 448.98474222\n",
      " 466.93335699 314.50978652 487.35037179 351.54086063 414.99598546]\n",
      "Mean: 397.3165461889447\n",
      "Standard deviation: 58.727758734771115\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren (3ft)\n",
    "forest_scores = cross_val_score(forest_reg_3ft, calls_prepared_3ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores_3ft = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores_3ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [385.71041998 382.12349407 403.40963545 431.7208966  477.29565251\n",
      " 493.14746301 369.52249662 516.34135601 406.48930653 444.20354691]\n",
      "Mean: 430.9964267694033\n",
      "Standard deviation: 48.005353328799806\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren (5ft)\n",
    "forest_scores = cross_val_score(forest_reg_5ft, calls_prepared_5ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores_5ft = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores_5ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model inkl. Metadaten exportieren\n",
    "forest_model = dict({\n",
    "    'model': forest_reg_3ft,\n",
    "    'metadata': {\n",
    "        'type': 'Random Forest',\n",
    "        'date': now,\n",
    "        'metrics': {\n",
    "            'Cross-val-RSME': forest_rmse_scores_3ft.mean()\n",
    "        }\n",
    "    }\n",
    "})\n",
    "joblib.dump(forest_model, open(\"../../webapp/total_forest_reg.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model initialisieren und trainieren\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "boost_reg_3ft = GradientBoostingRegressor()\n",
    "boost_reg_3ft.fit(calls_prepared_3ft, calls_labels)\n",
    "boost_reg_5ft = GradientBoostingRegressor()\n",
    "boost_reg_5ft.fit(calls_prepared_5ft, calls_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [380.22558856 306.88461924 359.13260136 413.17243472 437.33268099\n",
      " 468.73932697 310.51907691 486.03422999 348.78150519 414.74817047]\n",
      "Mean: 392.55702343970063\n",
      "Standard deviation: 58.92331542160704\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren (3ft)\n",
    "boost_scores = cross_val_score(boost_reg_3ft, calls_prepared_3ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "boost_rmse_scores_3ft = np.sqrt(-boost_scores)\n",
    "display_scores(boost_rmse_scores_3ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [371.23903629 306.55429502 364.00299241 402.67275048 444.02710578\n",
      " 472.03141993 324.72702088 480.41394562 354.11617922 417.11797991]\n",
      "Mean: 393.6902725541212\n",
      "Standard deviation: 56.67607973588272\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren (5ft)\n",
    "boost_scores = cross_val_score(boost_reg_5ft, calls_prepared_5ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "boost_rmse_scores_5ft = np.sqrt(-boost_scores)\n",
    "display_scores(boost_rmse_scores_5ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model inkl. Metadaten exportieren\n",
    "boost_model = dict({\n",
    "    'model': boost_reg_3ft,\n",
    "    'metadata': {\n",
    "        'type': 'Gradient Boosting',\n",
    "        'date': now,\n",
    "        'metrics': {\n",
    "            'Cross-val-RSME': boost_rmse_scores_3ft.mean()\n",
    "        }\n",
    "    }\n",
    "})\n",
    "joblib.dump(boost_model, open(\"../../webapp/total_boost_reg.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(batch_size=128, max_iter=1500)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model initialisieren und trainieren\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "nn_reg_3ft = MLPRegressor(batch_size=128, max_iter = 1500, learning_rate_init=0.001)\n",
    "nn_reg_3ft.fit(calls_prepared_3ft, calls_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(batch_size=128, max_iter=1500)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_reg_5ft = MLPRegressor(batch_size=128, max_iter = 1500, learning_rate_init=0.001)\n",
    "nn_reg_5ft.fit(calls_prepared_5ft, calls_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [369.39158304 401.78862892 478.28876533 438.38448113 400.20333815]\n",
      "Mean: 417.6113593145511\n",
      "Standard deviation: 37.39469216905511\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren (3ft)\n",
    "nn_scores = cross_val_score(nn_reg_3ft, calls_prepared_3ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "nn_rmse_scores_3ft = np.sqrt(-nn_scores)\n",
    "display_scores(nn_rmse_scores_3ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [370.51288101 405.28677035 477.87763895 438.59497074 400.67392775]\n",
      "Mean: 418.58923776015615\n",
      "Standard deviation: 36.67313435970404\n"
     ]
    }
   ],
   "source": [
    "#Model evaluieren (5ft)\n",
    "nn_scores = cross_val_score(nn_reg_5ft, calls_prepared_5ft, calls_labels, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "nn_rmse_scores_5ft = np.sqrt(-nn_scores)\n",
    "display_scores(nn_rmse_scores_5ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model inkl. Metadaten exportieren\n",
    "nn_model = dict({\n",
    "    'model': nn_reg_3ft,\n",
    "    'metadata': {\n",
    "        'type': 'Neural Network',\n",
    "        'date': now,\n",
    "        'metrics': {\n",
    "            'Cross-val-RSME': nn_rmse_scores_3ft.mean()\n",
    "        }\n",
    "    }\n",
    "})\n",
    "joblib.dump(nn_model, open(\"../../webapp/total_nn_reg.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [70, 80],\n",
       "                         'max_features': [2, 3], 'min_samples_leaf': [4, 5],\n",
       "                         'min_samples_split': [12, 14],\n",
       "                         'n_estimators': [900, 1000]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid ={\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [70,80],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [4, 5],\n",
    "    'min_samples_split': [12, 14],\n",
    "    'n_estimators': [900, 1000]\n",
    "}\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=3,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(calls_prepared_3ft, calls_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 70,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 14,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\specht\\AppData\\Local\\Continuum\\anaconda3\\envs\\lavisenv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "344.26978152976363"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model1 = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"UNLOADING_TOTAL\", axis=1)\n",
    "y_test = strat_test_set[\"UNLOADING_TOTAL\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline_3ft.transform(X_test)\n",
    "final_predictions = final_model1.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model inkl. Metadaten exportieren\n",
    "final_model = dict({\n",
    "    'model': final_model1,\n",
    "    'metadata': {\n",
    "        'type': 'Random Forest',\n",
    "        'date': now,\n",
    "        'metrics': {\n",
    "            'Cross-val-RSME': final_rmse\n",
    "        }\n",
    "    }\n",
    "})\n",
    "joblib.dump(final_model, open(\"../../webapp/total_final_reg.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\specht\\AppData\\Local\\Continuum\\anaconda3\\envs\\lavisenv\\lib\\site-packages\\plotly\\offline\\offline.py:562: UserWarning:\n",
      "\n",
      "Your filename `Random_Forest` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_series_plot(y_test, final_predictions, \"Random_Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning (Gradient Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'max_depth': [80], 'max_features': [2, 3],\n",
       "                         'min_samples_leaf': [3, 4],\n",
       "                         'min_samples_split': [12, 14],\n",
       "                         'n_estimators': [1000]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid ={\n",
    "    'max_depth': [80],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4],\n",
    "    'min_samples_split': [12, 14],\n",
    "    'n_estimators': [1000]\n",
    "}\n",
    "\n",
    "boost_reg = GradientBoostingRegressor()\n",
    "grid_search = GridSearchCV(boost_reg, param_grid, cv=3,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(calls_prepared_3ft, calls_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 80,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 14,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\specht\\AppData\\Local\\Continuum\\anaconda3\\envs\\lavisenv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:437: FutureWarning:\n",
      "\n",
      "Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "349.3753376578678"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model2 = grid_search.best_estimator_\n",
    "\n",
    "X_test_prepared = full_pipeline_3ft.transform(X_test)\n",
    "final_predictions = final_model2.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\specht\\AppData\\Local\\Continuum\\anaconda3\\envs\\lavisenv\\lib\\site-packages\\plotly\\offline\\offline.py:562: UserWarning:\n",
      "\n",
      "Your filename `Gradient_boosting` didn't end with .html. Adding .html to the end of your file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_series_plot(y_test, final_predictions, \"Gradient_boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
